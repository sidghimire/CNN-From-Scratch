{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X,train_y),(test_X,test_y)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X/255.0\n",
    "test_X = test_X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y,test_y=to_categorical(train_y,10),to_categorical(test_y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_X.reshape(-1,28,28,1)\n",
    "train_X=train_X.reshape(-1,28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]])"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self,num_filters,filter_size):\n",
    "        self.num_filters=num_filters\n",
    "        self.filter_size=filter_size\n",
    "        self.filters=np.random.randn(num_filters,filter_size,filter_size)/filter_size**2\n",
    "        \n",
    "    def iterate_regions(self,image):\n",
    "        h,w=image.shape\n",
    "        for i in range(h-self.filter_size+1):\n",
    "            for j in range(w-self.filter_size+1):\n",
    "                yield image[i:i+self.filter_size,j:j+self.filter_size],i,j\n",
    "        \n",
    "    \n",
    "    def forward(self,input):\n",
    "        self.last_input=input\n",
    "        h,w,_=input.shape\n",
    "        output_h=h-self.filter_size+1\n",
    "        output_w=w-self.filter_size+1\n",
    "        output=np.zeros((output_h,output_w,self.num_filters))\n",
    "        for region,i,j in self.iterate_regions(input[:,:,0]):\n",
    "            output[i,j]=np.sum(region*self.filters,axis=(1,2))\n",
    "        return output\n",
    "    \n",
    "    def backward(self, d_L_d_out, learn_rate):\n",
    "        d_L_d_filters = np.zeros(self.filters.shape)\n",
    "        h, w = self.last_input.shape[:2]\n",
    "\n",
    "        for region, i, j in self.iterate_regions(self.last_input[:, :, 0]):\n",
    "            for f in range(self.num_filters):\n",
    "                d_L_d_filters[f] += d_L_d_out[i, j, f] * region\n",
    "\n",
    "        # Update filters\n",
    "        self.filters -= learn_rate * d_L_d_filters\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    \n",
    "    def iterate_regions(self,image):\n",
    "        h,w,num_filters=image.shape\n",
    "        for i in range(0,h,2):\n",
    "            for j in range(0,w,2):\n",
    "                yield image[i:i+2,j:j+2],i//2,j//2\n",
    "    \n",
    "    \n",
    "    def forward(self,input):\n",
    "        self.last_input=input\n",
    "        h,w,num_filters=input.shape\n",
    "        output=np.zeros((h//2,w//2,num_filters))\n",
    "        for region,i,j in self.iterate_regions(input):\n",
    "            output[i,j]=np.max(region,axis=(0,1))\n",
    "        return output\n",
    "    \n",
    "    def backward(self, d_L_d_out):\n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "        for region, i, j in self.iterate_regions(self.last_input):\n",
    "            h, w, f = region.shape\n",
    "            amax = np.max(region, axis=(0, 1))\n",
    "\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for f2 in range(f):\n",
    "                        if region[i2, j2, f2] == amax[f2]:\n",
    "                            d_L_d_input[i*2+i2, j*2+j2, f2] = d_L_d_out[i, j, f2]\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self,input):\n",
    "        self.last_input_shape=input.shape\n",
    "        input=input.flatten()\n",
    "        self.last_input=input\n",
    "        exp=np.exp(input)\n",
    "        self.out=exp/np.sum(exp,axis=0)\n",
    "        return self.out        \n",
    "    \n",
    "    def backward(self,d_L_d_out,learn_rate):\n",
    "        d_out_d_t=np.diagflat(self.out)-np.outer(self.out,self.out)\n",
    "        d_L_d_t=np.dot(d_out_d_t,d_L_d_out)\n",
    "        return d_L_d_t.reshape(self.last_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    \n",
    "    def __init__(self,input_size,output_size):\n",
    "        self.weights=np.random.randn(input_size,output_size)\n",
    "        self.biases=np.zeros(output_size)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        self.last_input_shape=input.shape\n",
    "        self.last_input=input.flatten()\n",
    "        output=np.dot(self.last_input,self.weights)+self.biases\n",
    "        return output\n",
    "    \n",
    "    def backward(self, d_L_d_out, learn_rate):\n",
    "        d_L_d_out = d_L_d_out.reshape(1, -1)  # Ensure d_L_d_out is a 2D array\n",
    "        d_L_d_weights = np.dot(self.last_input.reshape(-1, 1), d_L_d_out)  # Reshape self.last_input to 2D\n",
    "        self.weights -= learn_rate * d_L_d_weights\n",
    "        self.biases -= learn_rate * np.sum(d_L_d_out, axis=0)\n",
    "\n",
    "        return np.dot(d_L_d_out, self.weights.T).reshape(self.last_input_shape)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=Conv2D(8,3)\n",
    "pool=MaxPool2D()\n",
    "softmax=Softmax()\n",
    "dense=Dense(13*13*8,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(image,label):\n",
    "    out=conv.forward(image)\n",
    "    out=pool.forward(out)\n",
    "    out=dense.forward(out)\n",
    "\n",
    "    out=softmax.forward(out)\n",
    "    loss=-np.log(out[label])\n",
    "    acc=1 if np.argmax(out)==label else 0\n",
    "\n",
    "    return out,loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(im,label,learn_rate=0.005):\n",
    "    out,loss,acc=forward(im,label)\n",
    "    grad=np.zeros(10)\n",
    "    grad[label]=-1/out[label]\n",
    "    \n",
    "    grad = softmax.backward(grad, learn_rate)\n",
    "    grad = dense.backward(grad, learn_rate)\n",
    "    grad = pool.backward(grad)\n",
    "    conv.backward(grad, learn_rate)\n",
    "    \n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3): \n",
    "    print(f\"--- Epoch {epoch+1} ---\")\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for i, (im, label) in enumerate(zip(train_X, train_y)):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"{i} steps completed\")\n",
    "\n",
    "        l, acc = train(im, np.argmax(label))\n",
    "        loss += l\n",
    "        num_correct += acc\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss} | Accuracy: {num_correct / len(train_X)}\")\n",
    "\n",
    "print(\"--- Testing ---\")\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(test_X, test_y):\n",
    "    _, l, acc = forward(im, np.argmax(label))\n",
    "    loss += l\n",
    "    num_correct += acc\n",
    "\n",
    "print(f\"Test Loss: {loss} | Test Accuracy: {num_correct / len(test_X)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
